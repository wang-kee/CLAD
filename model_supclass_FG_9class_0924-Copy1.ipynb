{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a100c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637d0af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pretrained models\n",
    "alexnet = torchvision.models.alexnet(pretrained = True)\n",
    "resnet = torchvision.models.resnet50(pretrained = True)\n",
    "vgg = torchvision.models.vgg16(pretrained = True)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "alexnet_9l = torch.load('alexnet_9l.pth')\n",
    "alexnet_9l.to(device)\n",
    "alexnet_9l.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d8c8cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Taken from https://github.com/MadryLab/backgrounds_challenge/blob/46d224bb02a296681eddbae44a49da9abb5ba038/tools/model_utils.py#L40\n",
    "\n",
    "resnet_9l = torchvision.models.resnet50(pretrained = False)\n",
    "resnet_9l.fc = nn.Linear(2048, 9)\n",
    "checkpoint = torch.load('in9l_resnet50.pt')\n",
    "\n",
    "# this is there to ensure only model part of the state_dict is used and other paramters are ignored\n",
    "state_dict_path = 'model'\n",
    "if not ('model' in checkpoint):\n",
    "    state_dict_path = 'state_dict'\n",
    "\n",
    "sd = checkpoint[state_dict_path]\n",
    "sd = {k[len('module.'):]:v for k,v in sd.items()}\n",
    "\n",
    "# To deal with some compatability issues\n",
    "model_dict = resnet_9l.state_dict()\n",
    "sd = {k: v for k, v in sd.items() if k in model_dict}\n",
    "model_dict.update(sd)\n",
    "resnet_9l.load_state_dict(model_dict)\n",
    "\n",
    "resnet_9l.eval()\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6923681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import test data\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform_ = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "folder_dir = 'imagenet/only_fg/val_1'\n",
    "data_test =  datasets.ImageFolder(root = folder_dir, transform = transform_,\n",
    "                                       target_transform = None)\n",
    "\n",
    "# show the test images\n",
    "\n",
    "fig = plt.figure(figsize = (12, math.ceil(len(data_test)/20)))\n",
    "fig.tight_layout()\n",
    "for i in range(len(data_test)):\n",
    "    img = data_test[i][0].permute(1, 2, 0)\n",
    "    img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "    plt.subplot(math.ceil(len(data_test)/20), 20, i+1)\n",
    "    plt.imshow(img_norm)\n",
    "    plt.title(i)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae98a9-9b3b-4a31-99ed-3174dc95d00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_dir = 'imagenet/test_0924'\n",
    "data_test_1 =  datasets.ImageFolder(root = folder_dir, transform = transform_,\n",
    "                                       target_transform = None)\n",
    "\n",
    "fig = plt.figure(figsize = (12, math.ceil(len(data_test)/20)))\n",
    "fig.tight_layout()\n",
    "for i in range(len(data_test_1)):\n",
    "    img = data_test[i][0].permute(1, 2, 0)\n",
    "    img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "    plt.subplot(math.ceil(len(data_test)/20), 20, i+1)\n",
    "    plt.imshow(img_norm)\n",
    "    plt.title(i)\n",
    "    plt.axis('off')\n",
    "plt.show() \n",
    "\n",
    "predictions = []\n",
    "for data in data_test_1:\n",
    "    logits = resnet_9l(data[0].unsqueeze(0))\n",
    "    pred = logits.max(dim=1)[1].item()\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3bbbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vector_a, vector_b):\n",
    "    \n",
    "    vector_a = np.mat(vector_a)\n",
    "    vector_b = np.mat(vector_b)\n",
    "    num = float(vector_a * vector_b.T)\n",
    "    denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "    cos = num / denom\n",
    "    sim = 0.5 + 0.5 * cos\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f80da8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make prediction\n",
    "\n",
    "pred_alexnet = []\n",
    "pred_resnet = []\n",
    "pred_vgg = []\n",
    "\n",
    "diff_alexnet = []\n",
    "diff_resnet = []\n",
    "diff_vgg = []\n",
    "\n",
    "logits_alexnet = None\n",
    "logits_resnet = None\n",
    "logits_vgg = None\n",
    "\n",
    "alexnet.eval()\n",
    "resnet.eval()\n",
    "vgg.eval()\n",
    "\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_classes = {int(i):x[1] for i,x in json.load(f).items()}\n",
    "    \n",
    "# use super_class \n",
    "for i, data in enumerate(data_test):\n",
    "    img = data[0].unsqueeze(0)\n",
    "    \n",
    "    logits_alexnet_last = logits_alexnet\n",
    "    logits_alexnet = alexnet(img)\n",
    "    pred = logits_alexnet.max(dim=1)[1].item()\n",
    "    # if the predictions are not included in the superclasses, put '*' near them\n",
    "    try:\n",
    "        pred_class = super_class.loc[pred].sup_class\n",
    "        pred_alexnet.append(pred_class)\n",
    "    except:\n",
    "        pred_alexnet.append(str(imagenet_classes[pred]) + '*')\n",
    "    \n",
    "    if (i%2) != 0:\n",
    "        diff_alexnet.append(cos_sim(logits_alexnet.detach().numpy(),logits_alexnet_last.detach().numpy()))\n",
    "    \n",
    "    logits_resnet_last = logits_resnet\n",
    "    logits_resnet = resnet(img)\n",
    "    pred = logits_resnet.max(dim=1)[1].item()\n",
    "    try:\n",
    "        pred_class = super_class.loc[pred].sup_class\n",
    "        pred_resnet.append(pred_class)\n",
    "    except:\n",
    "        pred_resnet.append(str(imagenet_classes[pred]) + '*')\n",
    "    \n",
    "    if (i%2) != 0:\n",
    "        diff_resnet.append(cos_sim(logits_resnet.detach().numpy(),logits_resnet_last.detach().numpy()))\n",
    "    \n",
    "    logits_vgg_last = logits_vgg\n",
    "    logits_vgg = vgg(img)\n",
    "    pred = logits_vgg.max(dim=1)[1].item()\n",
    "    try:\n",
    "        pred_class = super_class.loc[pred].sup_class\n",
    "        pred_vgg.append(pred_class)\n",
    "    except:\n",
    "        pred_vgg.append(str(imagenet_classes[pred]) + '*')\n",
    "    if (i%2) != 0:\n",
    "        diff_vgg.append(cos_sim(logits_vgg.detach().numpy(),logits_vgg_last.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c205d65-76d1-4b1e-9729-b697b2a13f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "\n",
    "pred_alexnet = []\n",
    "# pred_resnet = []\n",
    "# pred_vgg = []\n",
    "\n",
    "diff_alexnet = []\n",
    "# diff_resnet = []\n",
    "# diff_vgg = []\n",
    "\n",
    "logits_alexnet = []\n",
    "# logits_resnet = []\n",
    "# logits_vgg = None\n",
    "\n",
    "alexnet.eval()\n",
    "# resnet_9l.eval()\n",
    "# vgg.eval()\n",
    "    \n",
    "for i, data in enumerate(data_test):\n",
    "    img = data[0].unsqueeze(0).to(device)\n",
    "    \n",
    "#     logits_alexnet_last = logits_alexnet\n",
    "#     logits_alexnet = alexnet(img)\n",
    "#     pred = logits_alexnet.max(dim=1)[1].item()\n",
    "#     # if the predictions are not included in the superclasses, put '*' near them\n",
    "#     try:\n",
    "#         pred_class = super_class.loc[pred].sup_class\n",
    "#         pred_alexnet.append(pred_class)\n",
    "#     except:\n",
    "#         pred_alexnet.append(str(imagenet_classes[pred]) + '*')\n",
    "    \n",
    "#     if (i%2) != 0:\n",
    "#         diff_alexnet.append(cos_sim(logits_alexnet.detach().numpy(),logits_alexnet_last.detach().numpy()))\n",
    "    \n",
    "    # logits_resnet_last = logits_resnet\n",
    "    logits = alexnet_9l(img)\n",
    "    logits_alexnet.append(logits)\n",
    "    pred = logits.max(dim=1)[1].item()\n",
    "    pred_alexnet.append(pred)\n",
    "#     try:\n",
    "#         pred_class = super_class.loc[pred].sup_class\n",
    "#         pred_resnet.append(pred_class)\n",
    "#     except:\n",
    "#         pred_resnet.append(str(imagenet_classes[pred]) + '*')\n",
    "    \n",
    "#     if (i%2) != 0:\n",
    "#         diff_resnet.append(cos_sim(logits_resnet.detach().numpy(),logits_resnet_last.detach().numpy()))\n",
    "    \n",
    "#     logits_vgg_last = logits_vgg\n",
    "#     logits_vgg = vgg(img)\n",
    "#     pred = logits_vgg.max(dim=1)[1].item()\n",
    "#     try:\n",
    "#         pred_class = super_class.loc[pred].sup_class\n",
    "#         pred_vgg.append(pred_class)\n",
    "#     except:\n",
    "#         pred_vgg.append(str(imagenet_classes[pred]) + '*')\n",
    "#     if (i%2) != 0:\n",
    "#         diff_vgg.append(cos_sim(logits_vgg.detach().numpy(),logits_vgg_last.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8faf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record errors made\n",
    "\n",
    "n_subclass = len(data_test.classes)\n",
    "subclasses = data_test.classes[0:n_subclass]\n",
    "\n",
    "err_alexnet = dict(map(lambda x: [x,[]], subclasses))\n",
    "# err_resnet = dict(map(lambda x: [x,[]], subclasses))\n",
    "# err_vgg = dict(map(lambda x: [x,[]], subclasses))\n",
    "\n",
    "# use super_class \n",
    "for i in range(len(pred_alexnet)):\n",
    "    if pred_alexnet[i] != 0: # data_test.classes[data_test[i][1]]:\n",
    "    # if pred_alexnet[i] != imagenet_classes[data_test[i][1]]:\n",
    "        err_alexnet[data_test.classes[data_test[i][1]]].append((i, pred_alexnet[i]))\n",
    "#     if pred_resnet[i] != data_test.classes[data_test[i][1]]:\n",
    "#     # if pred_resnet[i] != imagenet_classes[data_test[i][1]]:\n",
    "#         err_resnet[data_test.classes[data_test[i][1]]].append((i, pred_resnet[i]))\n",
    "#     if pred_vgg[i] != data_test.classes[data_test[i][1]]:\n",
    "#     # if pred_vgg[i] != imagenet_classes[data_test[i][1]]:\n",
    "#         err_vgg[data_test.classes[data_test[i][1]]].append((i, pred_vgg[i]))\n",
    "\n",
    "print('errors made by alexnet: ' + '\\n')\n",
    "print(err_alexnet)\n",
    "# print('\\n' + 'errors made by resnet: ' + '\\n')\n",
    "# print(err_resnet)\n",
    "# print('\\n' + 'errors made by vgg: ' + '\\n')\n",
    "# print(err_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dd24cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the errors made by alexnet and resnet, the titles represent the false predictions\n",
    "\n",
    "for class_name in err_alexnet.keys():\n",
    "    \n",
    "    print('\\n' + '\\033[1m' + 'Errors made on {} by: '.format(class_name))\n",
    "    fig = plt.figure(figsize = (14, math.ceil(len(err_alexnet[class_name])/3.5)))\n",
    "    plt.suptitle('Alexnet', y = 1.01)\n",
    "    plt.subplots_adjust(wspace = 0.1, hspace = 0.1)\n",
    "    for i, data in enumerate(err_alexnet[class_name]):\n",
    "        num, false_pred = data[0], data[1]\n",
    "        img = data_test[num][0].permute(1, 2, 0)\n",
    "        img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "        plt.subplot(math.ceil(len(err_alexnet[class_name])/10), 10, i+1)\n",
    "        plt.imshow(img_norm)\n",
    "        plt.title(str(num) + '\\n' + str(false_pred), fontsize = 11)\n",
    "        plt.axis('off')\n",
    "    plt.show()    \n",
    "\n",
    "    fig = plt.figure(figsize = (14, math.ceil(len(err_resnet[class_name])/3.5)))\n",
    "    plt.suptitle('Resnet', y = 1.01)\n",
    "    plt.subplots_adjust(wspace = 0.1, hspace = 0.1)\n",
    "    for i, data in enumerate(err_resnet[class_name]):\n",
    "        num, false_pred = data[0], data[1]\n",
    "        img = data_test[num][0].permute(1, 2, 0)\n",
    "        img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "        plt.subplot(math.ceil(len(err_resnet[class_name])/10), 10, i+1)\n",
    "        plt.imshow(img_norm)\n",
    "        plt.title(str(num) + '\\n' + str(false_pred), fontsize = 11)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize = (14, math.ceil(len(err_vgg[class_name])/3.5)))\n",
    "    plt.suptitle('VGG', y = 1.01)\n",
    "    plt.subplots_adjust(wspace = 0.1, hspace = 0.1)\n",
    "    for i, data in enumerate(err_vgg[class_name]):\n",
    "        num, false_pred = data[0], data[1]\n",
    "        img = data_test[num][0].permute(1, 2, 0)\n",
    "        img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "        plt.subplot(math.ceil(len(err_vgg[class_name])/10), 10, i+1)\n",
    "        plt.imshow(img_norm)\n",
    "        plt.title(str(num) + '\\n' + str(false_pred), fontsize = 11)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7786cf7",
   "metadata": {},
   "source": [
    "#### Quantify the influence of background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9211e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_alexnet_nb = logits_alexnet[0:int(len(logits_alexnet)/2)]\n",
    "logits_alexnet_b = logits_alexnet[int(len(logits_alexnet)/2):]\n",
    "\n",
    "cos_similarities = []\n",
    "for i in range(len(logits_alexnet_nb)):\n",
    "    cos_similarities.append(cos_sim(logits_alexnet_nb[i].detach().to('cpu'), \n",
    "                                    logits_alexnet_b[i].detach().to('cpu')))\n",
    "\n",
    "height = (len(list(filter(lambda x: (0.6<=x) and (x <0.65), cos_similarities))),\n",
    "len(list(filter(lambda x: (0.65<=x) and (x <0.7), cos_similarities))),\n",
    "len(list(filter(lambda x: (0.7<=x) and (x <0.75), cos_similarities))),\n",
    "len(list(filter(lambda x: (0.75<=x) and (x <8), cos_similarities))),\n",
    "len(list(filter(lambda x: (0.8<=x) and (x <0.85), cos_similarities))),\n",
    "len(list(filter(lambda x: (0.85<=x) and (x <0.9), cos_similarities))),\n",
    "len(list(filter(lambda x: (0.9<=x) and (x <0.95), cos_similarities))),\n",
    "len(list(filter(lambda x: (0.95<=x) and (x <1), cos_similarities))))\n",
    "\n",
    "x_label = ['0.6-0.65', '0.65-0.7', '0.7-0.75', '0.75-0.8', '0.8-0.85', '0.85-0.9', '0.9-0.95', '0.95-1']\n",
    "plt.figure(figsize = (10,6))\n",
    "plt.bar(x_label, height)\n",
    "plt.title('Cosine Similarities')\n",
    "plt.ylabel('number of images')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f02e5cd",
   "metadata": {},
   "source": [
    "##### The remaining part is not related to the current task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1d5351",
   "metadata": {},
   "source": [
    "Testing the performance on stylized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cd16bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sti_name = 'filled-silhouettes'\n",
    "# class_name = 'bear'\n",
    "\n",
    "data_dir = 'texture-vs-shape-master/stimuli/' # + sti_name  + '/' + class_name + '/'\n",
    "\n",
    "data_sti =  datasets.ImageFolder(root = data_dir, transform = transform_,\n",
    "                                       target_transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "# pred_alex = []\n",
    "plt.figure(figsize = (15, math.ceil(len(data_sti)/5)))\n",
    "\n",
    "for i, data in enumerate(data_sti):\n",
    "    img = data[0]\n",
    "    pred = resnet(img.unsqueeze(0))\n",
    "    pred_class = str(imagenet_classes[pred.max(dim=1)[1].item()])\n",
    "    img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "    plt.subplot(math.ceil(len(data_sti)/10), 10, i+1)\n",
    "    plt.imshow(img_norm.permute(1, 2, 0))\n",
    "    plt.title(pred_class, fontsize = 11)\n",
    "    plt.axis('off')\n",
    "    if i == 600:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca438043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleted codes\n",
    "\n",
    "\"\"\"\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resi\n",
    "   \\ze((224, 224)),\n",
    "   transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.mean = torch.Tensor(mean)\n",
    "        self.std = torch.Tensor(std)\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean.type_as(x)[None,:,None,None]) / self.std.type_as(x)[None,:,None,None]\n",
    "\n",
    "norm = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_dir = 'ILSVRC2012_img_val/ILSVRC2012_val_00000008.JPEG'\n",
    "test_img = Image.open(data_dir)\n",
    "test_img = preprocess(test_img)[None,:,:,:]\n",
    "test_img_norm = norm(test_img)\n",
    "\n",
    "plt.imshow(test_img[0].numpy().transpose(1,2,0))\n",
    "\n",
    "alexnet.eval()\n",
    "\n",
    "pred = alexnet(test_img_norm)\n",
    "_, predicted = torch.max(pred, 1)\n",
    "\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_classes = {int(i):x[1] for i,x in json.load(f).items()}\n",
    "print('predicted label:{} '.format(int(predicted)) + str(imagenet_classes[pred.max(dim=1)[1].item()]))\n",
    "print('true label:{} '.format(int(labels[0][7])) + str(imagenet_classes[int(labels[0][7])]))\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
