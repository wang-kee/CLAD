{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6144c030-2e74-4e3c-a9b1-c006ba96bfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccab1ca-4ac0-4546-806a-e6c1cdf784a7",
   "metadata": {},
   "source": [
    "##### Using super classes:\n",
    "\n",
    "The following two cells respectively used the two methods in the email.\n",
    "\n",
    "The first method still has more than 500 classes, so I didn't use it.  \n",
    "However, for the second method:  \n",
    "Although it has only 13 super-classes, they only include about 300 original classes, and the rest are not included. I have to put '\\*' to the predictions which are not included in the 13 super-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c551b0-3a73-4b09-9922-fe811f9f1698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first method\n",
    "super_class = pd.read_csv('imagenet_hierarchy_of_categories.csv', index_col=None)\n",
    "super_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c374487-f175-409c-9ce4-f0f3f99d74b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# second method\n",
    "\n",
    "# create a dataframe 'super_class' to map the subclasses to their superclasses\n",
    "from robustness.tools.imagenet_helpers import common_superclass_wnid\n",
    "from robustness.tools.imagenet_helpers import ImageNetHierarchy\n",
    "\n",
    "in_path = 'imagenet'\n",
    "in_info_path = 'imagenet_info'\n",
    "in_hier = ImageNetHierarchy(in_path, in_info_path)\n",
    "\n",
    "\n",
    "# option 1: specify number of super classes\n",
    "# n_classes = 9\n",
    "# superclass_wnid, class_ranges, label_map = in_hier.get_superclasses(n_classes,\n",
    "#                                            # ancestor_wnid='n00001740',\n",
    "#                                            # superclass_lowest=['n02084071'],\n",
    "#                                            balanced=False)\n",
    "\n",
    "# option 2: load pre-specified super classes (maximum nb of super classes is 16)\n",
    "superclass_wnid = common_superclass_wnid('big_12')\n",
    "class_ranges, label_map = in_hier.get_subclasses(superclass_wnid,\n",
    "                                                 balanced=False)\n",
    "\n",
    "# add fish to the super classes\n",
    "fish_range = {0, 1, 2, 3, 4, 5, 6, 389, 390, 391, 392, 393, 394, 395, 396, 397}\n",
    "class_ranges.append(fish_range)\n",
    "label_map[12] = 'fish'\n",
    "\n",
    "super_class = pd.DataFrame(columns = ['class', 'sup_class'])\n",
    "\n",
    "for i, sub_classes in enumerate(class_ranges):\n",
    "    for sub_class in sub_classes:\n",
    "        new = pd.DataFrame({'class': sub_class, 'sup_class': label_map[i].split(',')[0]}, index = [1])\n",
    "        super_class = super_class.append(new, ignore_index = True)\n",
    "        \n",
    "super_class = super_class.set_index('class')\n",
    "super_class = super_class.sort_index()\n",
    "# super_class.to_csv('super_class.csv')\n",
    "\"\"\"\n",
    "super_class = pd.read_csv('super_class.csv', index_col = 'class')\n",
    "super_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022fe90-598e-4f76-9d9f-5c8b6f6b58c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pair(class_range_):   \n",
    "    pairs = np.empty(shape= [0, 2], dtype = int)\n",
    "    for i in list(sorted(class_range))[0:-1]:\n",
    "        pairs = np.concatenate((pairs, list(map(lambda x: (i, x), list(filter(lambda x: x>i, class_range_))))), axis=0)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2332546-f16f-4841-9113-9070f9002e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dis_mat = np.ones((1000, 1000)) - np.identity(1000)\n",
    "\n",
    "for n_class in range(1, 101):\n",
    "    superclass_wnid, class_ranges, label_map = in_hier.get_superclasses(n_class,\n",
    "                                               # ancestor_wnid='n00001740',\n",
    "                                               # superclass_lowest=['n02084071'],\n",
    "                                               balanced=False)\n",
    "    pairs = np.empty(shape= [0, 2], dtype = int)\n",
    "    for class_range in class_ranges:\n",
    "        pairs = np.concatenate((pairs, find_pair(class_range)), axis=0)\n",
    "    for pair in pairs:\n",
    "        dis_mat[tuple(pair)] = 1/n_class\n",
    "        \n",
    "#     if (n_class%10 == 0) or (n_class == 100):\n",
    "#         print(str(n_class) + '/100')\n",
    "#         print(dis_mat)\n",
    "        \n",
    "# construct symmetric matrix\n",
    "up = np.triu(dis_mat)\n",
    "dis_mat = up + up.T\n",
    "\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_classes = {int(i):x[1] for i,x in json.load(f).items()}\n",
    "    \n",
    "dis_mat_save = pd.DataFrame(dis_mat, columns = list(imagenet_classes.values()), \n",
    "                            index = list(imagenet_classes.values()))\n",
    "dis_mat_save.to_csv('dis_mat.csv')\n",
    "\n",
    "dis_mat\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c9791-daf3-494c-b19a-8de304fd9211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pretrained models\n",
    "alexnet = torchvision.models.alexnet(pretrained = True)\n",
    "resnet = torchvision.models.resnet50(pretrained = True)\n",
    "vgg = torchvision.models.vgg16(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd993f-6dba-4d9a-ba81-2a8e61e51085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_9 = torch.load('in9l_resnet50.pt') \n",
    "# resnet_9.eval()\n",
    "# resnet_9l = torchvision.models.resnet50(pretrained = False)\n",
    "aaa = torch.load('in9l_resnet50.pt') \n",
    "aaa\n",
    "\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc119c6-5327-41c6-b6b0-4e45c50a68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test data\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform_ = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "folder_dir = 'imagenet/only_fg/val_1'\n",
    "data_test =  datasets.ImageFolder(root = folder_dir, transform = transform_,\n",
    "                                       target_transform = None)\n",
    "\n",
    "# show the test images\n",
    "\n",
    "fig = plt.figure(figsize = (12, math.ceil(len(data_test)/20)))\n",
    "fig.tight_layout()\n",
    "for i in range(len(data_test)):\n",
    "    img = data_test[i][0].permute(1, 2, 0)\n",
    "    img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "    plt.subplot(math.ceil(len(data_test)/20), 20, i+1)\n",
    "    plt.imshow(img_norm)\n",
    "    plt.title(i)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13e3b15-41e5-4507-bf04-a2c43136c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vector_a, vector_b):\n",
    "    \n",
    "    vector_a = np.mat(vector_a)\n",
    "    vector_b = np.mat(vector_b)\n",
    "    num = float(vector_a * vector_b.T)\n",
    "    denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "    cos = num / denom\n",
    "    sim = 0.5 + 0.5 * cos\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6203a-5cc3-4ca7-9bf5-8f297761bf78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "\n",
    "pred_alexnet = []\n",
    "pred_resnet = []\n",
    "pred_vgg = []\n",
    "\n",
    "diff_alexnet = []\n",
    "diff_resnet = []\n",
    "diff_vgg = []\n",
    "\n",
    "logits_alexnet = None\n",
    "logits_resnet = None\n",
    "logits_vgg = None\n",
    "\n",
    "alexnet.eval()\n",
    "resnet.eval()\n",
    "vgg.eval()\n",
    "\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_classes = {int(i):x[1] for i,x in json.load(f).items()}\n",
    "    \n",
    "# use super_class \n",
    "for i, data in enumerate(data_test):\n",
    "    img = data[0].unsqueeze(0)\n",
    "    \n",
    "    logits_alexnet_last = logits_alexnet\n",
    "    logits_alexnet = alexnet(img)\n",
    "    pred = logits_alexnet.max(dim=1)[1].item()\n",
    "    # if the predictions are not included in the superclasses, put '*' near them\n",
    "    try:\n",
    "        pred_class = super_class.loc[pred].sup_class\n",
    "        pred_alexnet.append(pred_class)\n",
    "    except:\n",
    "        pred_alexnet.append(str(imagenet_classes[pred]) + '*')\n",
    "    \n",
    "    if (i%2) != 0:\n",
    "        diff_alexnet.append(cos_sim(logits_alexnet.detach().numpy(),logits_alexnet_last.detach().numpy()))\n",
    "    \n",
    "    logits_resnet_last = logits_resnet\n",
    "    logits_resnet = resnet(img)\n",
    "    pred = logits_resnet.max(dim=1)[1].item()\n",
    "    try:\n",
    "        pred_class = super_class.loc[pred].sup_class\n",
    "        pred_resnet.append(pred_class)\n",
    "    except:\n",
    "        pred_resnet.append(str(imagenet_classes[pred]) + '*')\n",
    "    \n",
    "    if (i%2) != 0:\n",
    "        diff_resnet.append(cos_sim(logits_resnet.detach().numpy(),logits_resnet_last.detach().numpy()))\n",
    "    \n",
    "    logits_vgg_last = logits_vgg\n",
    "    logits_vgg = vgg(img)\n",
    "    pred = logits_vgg.max(dim=1)[1].item()\n",
    "    try:\n",
    "        pred_class = super_class.loc[pred].sup_class\n",
    "        pred_vgg.append(pred_class)\n",
    "    except:\n",
    "        pred_vgg.append(str(imagenet_classes[pred]) + '*')\n",
    "    if (i%2) != 0:\n",
    "        diff_vgg.append(cos_sim(logits_vgg.detach().numpy(),logits_vgg_last.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a8d46-1d25-47b2-a404-cbff39acf9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ae0c82-3ed3-45cf-a92c-c06d945cbccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# record errors made\n",
    "\n",
    "n_subclass = len(data_test.classes)\n",
    "subclasses = data_test.classes[0:n_subclass]\n",
    "\n",
    "err_alexnet = dict(map(lambda x: [x,[]], subclasses))\n",
    "err_resnet = dict(map(lambda x: [x,[]], subclasses))\n",
    "err_vgg = dict(map(lambda x: [x,[]], subclasses))\n",
    "\n",
    "# use super_class \n",
    "for i in range(len(pred_alexnet)):\n",
    "    if pred_alexnet[i] != data_test.classes[data_test[i][1]]:\n",
    "    # if pred_alexnet[i] != imagenet_classes[data_test[i][1]]:\n",
    "        err_alexnet[data_test.classes[data_test[i][1]]].append((i, pred_alexnet[i]))\n",
    "    if pred_resnet[i] != data_test.classes[data_test[i][1]]:\n",
    "    # if pred_resnet[i] != imagenet_classes[data_test[i][1]]:\n",
    "        err_resnet[data_test.classes[data_test[i][1]]].append((i, pred_resnet[i]))\n",
    "    if pred_vgg[i] != data_test.classes[data_test[i][1]]:\n",
    "    # if pred_vgg[i] != imagenet_classes[data_test[i][1]]:\n",
    "        err_vgg[data_test.classes[data_test[i][1]]].append((i, pred_vgg[i]))\n",
    "\n",
    "print('errors made by alexnet: ' + '\\n')\n",
    "print(err_alexnet)\n",
    "print('\\n' + 'errors made by resnet: ' + '\\n')\n",
    "print(err_resnet)\n",
    "print('\\n' + 'errors made by vgg: ' + '\\n')\n",
    "print(err_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262ba4da-367a-48d6-b919-aafd0e2c5c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the errors made by alexnet and resnet, the titles represent the false predictions\n",
    "\n",
    "for class_name in err_alexnet.keys():\n",
    "    \n",
    "    print('\\n' + '\\033[1m' + 'Errors made on {} by: '.format(class_name))\n",
    "    fig = plt.figure(figsize = (14, math.ceil(len(err_alexnet[class_name])/3.5)))\n",
    "    plt.suptitle('Alexnet', y = 1.01)\n",
    "    plt.subplots_adjust(wspace = 0.1, hspace = 0.1)\n",
    "    for i, data in enumerate(err_alexnet[class_name]):\n",
    "        num, false_pred = data[0], data[1]\n",
    "        img = data_test[num][0].permute(1, 2, 0)\n",
    "        img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "        plt.subplot(math.ceil(len(err_alexnet[class_name])/10), 10, i+1)\n",
    "        plt.imshow(img_norm)\n",
    "        plt.title(str(num) + '\\n' + false_pred, fontsize = 11)\n",
    "        plt.axis('off')\n",
    "    plt.show()    \n",
    "\n",
    "    fig = plt.figure(figsize = (14, math.ceil(len(err_resnet[class_name])/3.5)))\n",
    "    plt.suptitle('Resnet', y = 1.01)\n",
    "    plt.subplots_adjust(wspace = 0.1, hspace = 0.1)\n",
    "    for i, data in enumerate(err_resnet[class_name]):\n",
    "        num, false_pred = data[0], data[1]\n",
    "        img = data_test[num][0].permute(1, 2, 0)\n",
    "        img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "        plt.subplot(math.ceil(len(err_resnet[class_name])/10), 10, i+1)\n",
    "        plt.imshow(img_norm)\n",
    "        plt.title(str(num) + '\\n' + false_pred, fontsize = 11)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize = (14, math.ceil(len(err_vgg[class_name])/3.5)))\n",
    "    plt.suptitle('VGG', y = 1.01)\n",
    "    plt.subplots_adjust(wspace = 0.1, hspace = 0.1)\n",
    "    for i, data in enumerate(err_vgg[class_name]):\n",
    "        num, false_pred = data[0], data[1]\n",
    "        img = data_test[num][0].permute(1, 2, 0)\n",
    "        img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "        plt.subplot(math.ceil(len(err_vgg[class_name])/10), 10, i+1)\n",
    "        plt.imshow(img_norm)\n",
    "        plt.title(str(num) + '\\n' + false_pred, fontsize = 11)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b12e5a4-1d71-46c2-8ad5-10f38000e5fb",
   "metadata": {},
   "source": [
    "#### Quantify the influence of background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c127b35-6b54-4bfd-845a-8d9ee8ce5e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_resnet_nb = logits_resnet[0:len(logits_resnet)/2]\n",
    "logits_resnet_b = logits_resnet[len(logits_resnet):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c10e67-e9c2-4936-a7f5-96d29ac9f51f",
   "metadata": {},
   "source": [
    "##### The remaining part is not related to the current task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf33eb-06ec-4e03-a7fa-d3a3e65b18e8",
   "metadata": {},
   "source": [
    "Testing the performance on stylized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9fdc58-e73d-4f54-a411-204c427aed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sti_name = 'filled-silhouettes'\n",
    "# class_name = 'bear'\n",
    "\n",
    "data_dir = 'texture-vs-shape-master/stimuli/' # + sti_name  + '/' + class_name + '/'\n",
    "\n",
    "data_sti =  datasets.ImageFolder(root = data_dir, transform = transform_,\n",
    "                                       target_transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00529cc-f753-4b82-b260-40e34fc87f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "# pred_alex = []\n",
    "plt.figure(figsize = (15, math.ceil(len(data_sti)/5)))\n",
    "\n",
    "for i, data in enumerate(data_sti):\n",
    "    img = data[0]\n",
    "    pred = resnet(img.unsqueeze(0))\n",
    "    pred_class = str(imagenet_classes[pred.max(dim=1)[1].item()])\n",
    "    img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "    plt.subplot(math.ceil(len(data_sti)/10), 10, i+1)\n",
    "    plt.imshow(img_norm.permute(1, 2, 0))\n",
    "    plt.title(pred_class, fontsize = 11)\n",
    "    plt.axis('off')\n",
    "    if i == 600:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7877f0a-f4d5-4114-b472-8baf63bb1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleted codes\n",
    "\n",
    "\"\"\"\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resi\n",
    "   \\ze((224, 224)),\n",
    "   transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.mean = torch.Tensor(mean)\n",
    "        self.std = torch.Tensor(std)\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean.type_as(x)[None,:,None,None]) / self.std.type_as(x)[None,:,None,None]\n",
    "\n",
    "norm = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_dir = 'ILSVRC2012_img_val/ILSVRC2012_val_00000008.JPEG'\n",
    "test_img = Image.open(data_dir)\n",
    "test_img = preprocess(test_img)[None,:,:,:]\n",
    "test_img_norm = norm(test_img)\n",
    "\n",
    "plt.imshow(test_img[0].numpy().transpose(1,2,0))\n",
    "\n",
    "alexnet.eval()\n",
    "\n",
    "pred = alexnet(test_img_norm)\n",
    "_, predicted = torch.max(pred, 1)\n",
    "\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_classes = {int(i):x[1] for i,x in json.load(f).items()}\n",
    "print('predicted label:{} '.format(int(predicted)) + str(imagenet_classes[pred.max(dim=1)[1].item()]))\n",
    "print('true label:{} '.format(int(labels[0][7])) + str(imagenet_classes[int(labels[0][7])]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20ca590-6d5c-4fe6-9b14-8da150773bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e2a10e-c881-4bf9-9795-8f970f59a319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
