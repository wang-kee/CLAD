{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using super classes:\n",
    "\n",
    "The following two cells respectively used the two methods in the email.\n",
    "\n",
    "The first method still has more than 500 classes, so I didn't use it.  \n",
    "However, for the second method:  \n",
    "Although it has only 13 super-classes, they only include about 300 original classes, and the rest are not included. I have to put '\\*' to the predictions which are not included in the 13 super-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first method\n",
    "super_class = pd.read_csv('imagenet_hierarchy_of_categories.csv', index_col=None)\n",
    "super_class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# second method\n",
    "\n",
    "# create a dataframe 'super_class' to map the subclasses to their superclasses\n",
    "from robustness.tools.imagenet_helpers import common_superclass_wnid\n",
    "from robustness.tools.imagenet_helpers import ImageNetHierarchy\n",
    "\n",
    "in_path = 'imagenet'\n",
    "in_info_path = 'imagenet_info'\n",
    "in_hier = ImageNetHierarchy(in_path, in_info_path)\n",
    "\n",
    "\n",
    "# option 1: specify number of super classes\n",
    "# n_classes = 9\n",
    "# superclass_wnid, class_ranges, label_map = in_hier.get_superclasses(n_classes,\n",
    "#                                            # ancestor_wnid='n00001740',\n",
    "#                                            # superclass_lowest=['n02084071'],\n",
    "#                                            balanced=False)\n",
    "\n",
    "# option 2: load pre-specified super classes (maximum nb of super classes is 16)\n",
    "superclass_wnid = common_superclass_wnid('big_12')\n",
    "class_ranges, label_map = in_hier.get_subclasses(superclass_wnid,\n",
    "                                                 balanced=False)\n",
    "\n",
    "# add fish to the super classes\n",
    "fish_range = {0, 1, 2, 3, 4, 5, 6, 389, 390, 391, 392, 393, 394, 395, 396, 397}\n",
    "class_ranges.append(fish_range)\n",
    "label_map[12] = 'fish'\n",
    "\n",
    "super_class = pd.DataFrame(columns = ['class', 'sup_class'])\n",
    "\n",
    "for i, sub_classes in enumerate(class_ranges):\n",
    "    for sub_class in sub_classes:\n",
    "        new = pd.DataFrame({'class': sub_class, 'sup_class': label_map[i].split(',')[0]}, index = [1])\n",
    "        super_class = super_class.append(new, ignore_index = True)\n",
    "        \n",
    "super_class = super_class.set_index('class')\n",
    "super_class = super_class.sort_index()\n",
    "# super_class.to_csv('super_class.csv')\n",
    "\"\"\"\n",
    "super_class = pd.read_csv('super_class.csv', index_col = 'class')\n",
    "super_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_pair(class_range_):   \n",
    "    pairs = np.empty(shape= [0, 2], dtype = int)\n",
    "    for i in list(sorted(class_range))[0:-1]:\n",
    "        pairs = np.concatenate((pairs, list(map(lambda x: (i, x), list(filter(lambda x: x>i, class_range_))))), axis=0)\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dis_mat = np.ones((1000, 1000)) - np.identity(1000)\n",
    "\n",
    "for n_class in range(1, 101):\n",
    "    superclass_wnid, class_ranges, label_map = in_hier.get_superclasses(n_class,\n",
    "                                               # ancestor_wnid='n00001740',\n",
    "                                               # superclass_lowest=['n02084071'],\n",
    "                                               balanced=False)\n",
    "    pairs = np.empty(shape= [0, 2], dtype = int)\n",
    "    for class_range in class_ranges:\n",
    "        pairs = np.concatenate((pairs, find_pair(class_range)), axis=0)\n",
    "    for pair in pairs:\n",
    "        dis_mat[tuple(pair)] = 1/n_class\n",
    "        \n",
    "#     if (n_class%10 == 0) or (n_class == 100):\n",
    "#         print(str(n_class) + '/100')\n",
    "#         print(dis_mat)\n",
    "        \n",
    "# construct symmetric matrix\n",
    "up = np.triu(dis_mat)\n",
    "dis_mat = up + up.T\n",
    "\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_classes = {int(i):x[1] for i,x in json.load(f).items()}\n",
    "    \n",
    "dis_mat_save = pd.DataFrame(dis_mat, columns = list(imagenet_classes.values()), \n",
    "                            index = list(imagenet_classes.values()))\n",
    "dis_mat_save.to_csv('dis_mat.csv')\n",
    "\n",
    "dis_mat\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pretrained models\n",
    "alexnet = torchvision.models.alexnet(pretrained = True)\n",
    "resnet = torchvision.models.resnet50(pretrained = True)\n",
    "vgg = torchvision.models.vgg16(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taken from https://github.com/MadryLab/backgrounds_challenge/blob/46d224bb02a296681eddbae44a49da9abb5ba038/tools/model_utils.py#L40\n",
    "\n",
    "resnet_9l = torchvision.models.resnet50(pretrained = False)\n",
    "checkpoint = torch.load('in9l_resnet50.pt')\n",
    "\n",
    "# this is there to ensure only model part of the state_dict is used and other paramters are ignored\n",
    "state_dict_path = 'model'\n",
    "if not ('model' in checkpoint):\n",
    "    state_dict_path = 'state_dict'\n",
    "\n",
    "sd = checkpoint[state_dict_path]\n",
    "sd = {k[len('module.'):]:v for k,v in sd.items()}\n",
    "\n",
    "# To deal with some compatability issues\n",
    "model_dict = resnet_9l.state_dict()\n",
    "sd = {k: v for k, v in sd.items() if k in model_dict}\n",
    "model_dict.update(sd)\n",
    "resnet_9l.load_state_dict(model_dict)\n",
    "\n",
    "resnet_9l.eval()\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import test data\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "transform_ = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "folder_dir = 'imagenet/only_fg/val_1'\n",
    "data_test =  datasets.ImageFolder(root = folder_dir, transform = transform_,\n",
    "                                       target_transform = None)\n",
    "\n",
    "# show the test images\n",
    "\n",
    "fig = plt.figure(figsize = (12, math.ceil(len(data_test)/20)))\n",
    "fig.tight_layout()\n",
    "for i in range(len(data_test)):\n",
    "    img = data_test[i][0].permute(1, 2, 0)\n",
    "    img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "    plt.subplot(math.ceil(len(data_test)/20), 20, i+1)\n",
    "    plt.imshow(img_norm)\n",
    "    plt.title(i)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(vector_a, vector_b):\n",
    "    \n",
    "    vector_a = np.mat(vector_a)\n",
    "    vector_b = np.mat(vector_b)\n",
    "    num = float(vector_a * vector_b.T)\n",
    "    denom = np.linalg.norm(vector_a) * np.linalg.norm(vector_b)\n",
    "    cos = num / denom\n",
    "    sim = 0.5 + 0.5 * cos\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "\n",
    "pred_alexnet = []\n",
    "pred_resnet = []\n",
    "pred_vgg = []\n",
    "\n",
    "diff_alexnet = []\n",
    "diff_resnet = []\n",
    "diff_vgg = []\n",
    "\n",
    "logits_alexnet = None\n",
    "logits_resnet = None\n",
    "logits_vgg = None\n",
    "\n",
    "alexnet.eval()\n",
    "resnet.eval()\n",
    "vgg.eval()\n",
    "\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_classes = {int(i):x[1] for i,x in json.load(f).items()}\n",
    "    \n",
    "# use super_class \n",
    "for i, data in enumerate(data_test):\n",
    "    img = data[0].unsqueeze(0)\n",
    "    \n",
    "    logits_alexnet_last = logits_alexnet\n",
    "    logits_alexnet = alexnet(img)\n",
    "    pred = logits_alexnet.max(dim=1)[1].item()\n",
    "    # if the predictions are not included in the superclasses, put '*' near them\n",
    "    try:\n",
    "        pred_class = super_class.loc[pred].sup_class\n",
    "        pred_alexnet.append(pred_class)\n",
    "    except:\n",
    "        pred_alexnet.append(str(imagenet_classes[pred]) + '*')\n",
    "    \n",
    "    if (i%2) != 0:\n",
    "        diff_alexnet.append(cos_sim(logits_alexnet.detach().numpy(),logits_alexnet_last.detach().numpy()))\n",
    "    \n",
    "    logits_resnet_last = logits_resnet\n",
    "    logits_resnet = resnet(img)\n",
    "    pred = logits_resnet.max(dim=1)[1].item()\n",
    "    try:\n",
    "        pred_class = super_class.loc[pred].sup_class\n",
    "        pred_resnet.append(pred_class)\n",
    "    except:\n",
    "        pred_resnet.append(str(imagenet_classes[pred]) + '*')\n",
    "    \n",
    "    if (i%2) != 0:\n",
    "        diff_resnet.append(cos_sim(logits_resnet.detach().numpy(),logits_resnet_last.detach().numpy()))\n",
    "    \n",
    "    logits_vgg_last = logits_vgg\n",
    "    logits_vgg = vgg(img)\n",
    "    pred = logits_vgg.max(dim=1)[1].item()\n",
    "    try:\n",
    "        pred_class = super_class.loc[pred].sup_class\n",
    "        pred_vgg.append(pred_class)\n",
    "    except:\n",
    "        pred_vgg.append(str(imagenet_classes[pred]) + '*')\n",
    "    if (i%2) != 0:\n",
    "        diff_vgg.append(cos_sim(logits_vgg.detach().numpy(),logits_vgg_last.detach().numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff_alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# record errors made\n",
    "\n",
    "n_subclass = len(data_test.classes)\n",
    "subclasses = data_test.classes[0:n_subclass]\n",
    "\n",
    "err_alexnet = dict(map(lambda x: [x,[]], subclasses))\n",
    "err_resnet = dict(map(lambda x: [x,[]], subclasses))\n",
    "err_vgg = dict(map(lambda x: [x,[]], subclasses))\n",
    "\n",
    "# use super_class \n",
    "for i in range(len(pred_alexnet)):\n",
    "    if pred_alexnet[i] != data_test.classes[data_test[i][1]]:\n",
    "    # if pred_alexnet[i] != imagenet_classes[data_test[i][1]]:\n",
    "        err_alexnet[data_test.classes[data_test[i][1]]].append((i, pred_alexnet[i]))\n",
    "    if pred_resnet[i] != data_test.classes[data_test[i][1]]:\n",
    "    # if pred_resnet[i] != imagenet_classes[data_test[i][1]]:\n",
    "        err_resnet[data_test.classes[data_test[i][1]]].append((i, pred_resnet[i]))\n",
    "    if pred_vgg[i] != data_test.classes[data_test[i][1]]:\n",
    "    # if pred_vgg[i] != imagenet_classes[data_test[i][1]]:\n",
    "        err_vgg[data_test.classes[data_test[i][1]]].append((i, pred_vgg[i]))\n",
    "\n",
    "print('errors made by alexnet: ' + '\\n')\n",
    "print(err_alexnet)\n",
    "print('\\n' + 'errors made by resnet: ' + '\\n')\n",
    "print(err_resnet)\n",
    "print('\\n' + 'errors made by vgg: ' + '\\n')\n",
    "print(err_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the errors made by alexnet and resnet, the titles represent the false predictions\n",
    "\n",
    "for class_name in err_alexnet.keys():\n",
    "    \n",
    "    print('\\n' + '\\033[1m' + 'Errors made on {} by: '.format(class_name))\n",
    "    fig = plt.figure(figsize = (14, math.ceil(len(err_alexnet[class_name])/3.5)))\n",
    "    plt.suptitle('Alexnet', y = 1.01)\n",
    "    plt.subplots_adjust(wspace = 0.1, hspace = 0.1)\n",
    "    for i, data in enumerate(err_alexnet[class_name]):\n",
    "        num, false_pred = data[0], data[1]\n",
    "        img = data_test[num][0].permute(1, 2, 0)\n",
    "        img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "        plt.subplot(math.ceil(len(err_alexnet[class_name])/10), 10, i+1)\n",
    "        plt.imshow(img_norm)\n",
    "        plt.title(str(num) + '\\n' + false_pred, fontsize = 11)\n",
    "        plt.axis('off')\n",
    "    plt.show()    \n",
    "\n",
    "    fig = plt.figure(figsize = (14, math.ceil(len(err_resnet[class_name])/3.5)))\n",
    "    plt.suptitle('Resnet', y = 1.01)\n",
    "    plt.subplots_adjust(wspace = 0.1, hspace = 0.1)\n",
    "    for i, data in enumerate(err_resnet[class_name]):\n",
    "        num, false_pred = data[0], data[1]\n",
    "        img = data_test[num][0].permute(1, 2, 0)\n",
    "        img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "        plt.subplot(math.ceil(len(err_resnet[class_name])/10), 10, i+1)\n",
    "        plt.imshow(img_norm)\n",
    "        plt.title(str(num) + '\\n' + false_pred, fontsize = 11)\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    fig = plt.figure(figsize = (14, math.ceil(len(err_vgg[class_name])/3.5)))\n",
    "    plt.suptitle('VGG', y = 1.01)\n",
    "    plt.subplots_adjust(wspace = 0.1, hspace = 0.1)\n",
    "    for i, data in enumerate(err_vgg[class_name]):\n",
    "        num, false_pred = data[0], data[1]\n",
    "        img = data_test[num][0].permute(1, 2, 0)\n",
    "        img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "        plt.subplot(math.ceil(len(err_vgg[class_name])/10), 10, i+1)\n",
    "        plt.imshow(img_norm)\n",
    "        plt.title(str(num) + '\\n' + false_pred, fontsize = 11)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantify the influence of background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_resnet_nb = logits_resnet[0:len(logits_resnet)/2]\n",
    "logits_resnet_b = logits_resnet[len(logits_resnet):]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The remaining part is not related to the current task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the performance on stylized images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sti_name = 'filled-silhouettes'\n",
    "# class_name = 'bear'\n",
    "\n",
    "data_dir = 'texture-vs-shape-master/stimuli/' # + sti_name  + '/' + class_name + '/'\n",
    "\n",
    "data_sti =  datasets.ImageFolder(root = data_dir, transform = transform_,\n",
    "                                       target_transform = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.eval()\n",
    "# pred_alex = []\n",
    "plt.figure(figsize = (15, math.ceil(len(data_sti)/5)))\n",
    "\n",
    "for i, data in enumerate(data_sti):\n",
    "    img = data[0]\n",
    "    pred = resnet(img.unsqueeze(0))\n",
    "    pred_class = str(imagenet_classes[pred.max(dim=1)[1].item()])\n",
    "    img_norm = (img - img.min()) / (img.max() - img.min())\n",
    "    plt.subplot(math.ceil(len(data_sti)/10), 10, i+1)\n",
    "    plt.imshow(img_norm.permute(1, 2, 0))\n",
    "    plt.title(pred_class, fontsize = 11)\n",
    "    plt.axis('off')\n",
    "    if i == 600:\n",
    "        break\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleted codes\n",
    "\n",
    "\"\"\"\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resi\n",
    "   \\ze((224, 224)),\n",
    "   transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class Normalize(nn.Module):\n",
    "    def __init__(self, mean, std):\n",
    "        super(Normalize, self).__init__()\n",
    "        self.mean = torch.Tensor(mean)\n",
    "        self.std = torch.Tensor(std)\n",
    "    def forward(self, x):\n",
    "        return (x - self.mean.type_as(x)[None,:,None,None]) / self.std.type_as(x)[None,:,None,None]\n",
    "\n",
    "norm = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "data_dir = 'ILSVRC2012_img_val/ILSVRC2012_val_00000008.JPEG'\n",
    "test_img = Image.open(data_dir)\n",
    "test_img = preprocess(test_img)[None,:,:,:]\n",
    "test_img_norm = norm(test_img)\n",
    "\n",
    "plt.imshow(test_img[0].numpy().transpose(1,2,0))\n",
    "\n",
    "alexnet.eval()\n",
    "\n",
    "pred = alexnet(test_img_norm)\n",
    "_, predicted = torch.max(pred, 1)\n",
    "\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_classes = {int(i):x[1] for i,x in json.load(f).items()}\n",
    "print('predicted label:{} '.format(int(predicted)) + str(imagenet_classes[pred.max(dim=1)[1].item()]))\n",
    "print('true label:{} '.format(int(labels[0][7])) + str(imagenet_classes[int(labels[0][7])]))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
